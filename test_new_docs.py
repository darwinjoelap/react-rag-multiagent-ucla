"""
Script de diagnÃ³stico para verificar documentos indexados
y validar que los nuevos PDFs estÃ¡n siendo recuperados correctamente
"""

import sys
sys.path.append('.')

from app.services.vector_store import VectorStoreService
from app.services.embeddings import EmbeddingsService

def print_header(text):
    """Imprime un encabezado destacado"""
    print("\n" + "=" * 80)
    print(text.center(80))
    print("=" * 80)

def test_new_documents():
    print_header("ğŸ”¬ DIAGNÃ“STICO DE DOCUMENTOS INDEXADOS")
    
    # Inicializar servicios
    print("\nâ³ Inicializando servicios...")
    embeddings = EmbeddingsService()
    vector_store = VectorStoreService(embeddings)
    print("âœ… Servicios inicializados")
    
    # ============================================================================
    # 1. DISTRIBUCIÃ“N POR FUENTE
    # ============================================================================
    print_header("ğŸ“Š DISTRIBUCIÃ“N DE DOCUMENTOS POR FUENTE")
    
    all_docs = vector_store.collection.get()
    sources = {}
    
    for metadata in all_docs['metadatas']:
        source = metadata.get('source', 'unknown')
        filename = source.split('/')[-1] if '/' in source else source
        sources[filename] = sources.get(filename, 0) + 1
    
    print("\nğŸ“ Archivos indexados:")
    for filename, count in sorted(sources.items(), key=lambda x: x[1], reverse=True):
        bar = "â–ˆ" * min(count // 10, 50)
        print(f"  â€¢ {filename:60s} {count:4d} chunks {bar}")
    
    print(f"\nğŸ“ˆ Resumen:")
    print(f"  â€¢ Total de fuentes: {len(sources)}")
    print(f"  â€¢ Total de chunks: {sum(sources.values())}")
    
    # ============================================================================
    # 2. VERIFICACIÃ“N DE ARCHIVOS NUEVOS
    # ============================================================================
    print_header("ğŸ“‹ VERIFICACIÃ“N DE ARCHIVOS NUEVOS")
    
    new_files = [
        "Redes Neuronales Artificiales.pdf",
        "BÃºsqueda HeurÃ­stica en Inteligencia Artificial",
        "Machine Learning.pdf",
        "MÃ³dulo2_Agentes.pdf",
        "IntroducciÃ³n al Machine Learning.pdf",
        "IntroducciÃ³n al ML.pdf",
        "Machine Learning_Part1 (Spanish).pdf",
    ]
    
    print("\nâœ“ Verificando archivos nuevos:")
    for new_file in new_files:
        found = any(new_file.lower() in filename.lower() for filename in sources.keys())
        count = next((cnt for filename, cnt in sources.items() if new_file.lower() in filename.lower()), 0)
        
        if found:
            print(f"  âœ… {new_file:60s} {count:4d} chunks")
        else:
            print(f"  âŒ {new_file:60s} NO ENCONTRADO")
    
    # ============================================================================
    # 3. PRUEBAS DE BÃšSQUEDA ESPECÃFICAS
    # ============================================================================
    print_header("ğŸ” PRUEBAS DE BÃšSQUEDA ESPECÃFICAS")
    
    test_queries = [
        {
            "query": "redes neuronales artificiales",
            "expected": "Redes Neuronales Artificiales.pdf",
            "description": "DeberÃ­a recuperar el PDF de Redes Neuronales"
        },
        {
            "query": "bÃºsqueda heurÃ­stica en inteligencia artificial",
            "expected": "BÃºsqueda HeurÃ­stica",
            "description": "DeberÃ­a recuperar el PDF de BÃºsqueda HeurÃ­stica"
        },
        {
            "query": "machine learning supervisado no supervisado",
            "expected": "Machine Learning",
            "description": "DeberÃ­a recuperar algÃºn PDF de Machine Learning"
        },
        {
            "query": "agente inteligente racionalidad",
            "expected": "MÃ³dulo2_Agentes.pdf",
            "description": "DeberÃ­a recuperar el PDF de Agentes"
        },
        {
            "query": "perceptrÃ³n multicapa backpropagation",
            "expected": "Redes Neuronales",
            "description": "DeberÃ­a recuperar contenido sobre redes neuronales"
        },
    ]
    
    for i, test in enumerate(test_queries, 1):
        query = test["query"]
        expected = test["expected"]
        description = test["description"]
        
        print(f"\n{'â”€' * 80}")
        print(f"ğŸ” Prueba {i}/{len(test_queries)}: {description}")
        print(f"   Query: '{query}'")
        print(f"   Esperado: {expected}")
        
        results = vector_store.search(query, top_k=5)
        
        if results:
            print(f"   âœ… {len(results)} resultados encontrados:")
            found_expected = False
            
            for j, doc in enumerate(results, 1):
                source = doc['metadata'].get('source', 'unknown')
                filename = source.split('/')[-1] if '/' in source else source
                similarity = doc['similarity']
                
                # Marcar si encontramos el archivo esperado
                is_expected = expected.lower() in filename.lower()
                marker = "â­" if is_expected else "  "
                
                if is_expected:
                    found_expected = True
                
                print(f"   {marker} [{j}] {filename:50s} (sim={similarity:.4f})")
            
            if found_expected:
                print(f"   âœ… Ã‰XITO: Se encontrÃ³ '{expected}' en los resultados")
            else:
                print(f"   âš ï¸  ADVERTENCIA: No se encontrÃ³ '{expected}' en los top 5")
        else:
            print("   âŒ Sin resultados")
    
    # ============================================================================
    # 4. ANÃLISIS DE CALIDAD DE EMBEDDINGS
    # ============================================================================
    print_header("ğŸ“Š ANÃLISIS DE CALIDAD DE SIMILITUD")
    
    quality_tests = [
        ("redes neuronales", 0.25),
        ("machine learning", 0.25),
        ("inteligencia artificial", 0.20),
        ("agente inteligente", 0.25),
    ]
    
    print("\nğŸ¯ Umbrales de similitud esperados:")
    for query, expected_threshold in quality_tests:
        results = vector_store.search(query, top_k=3)
        if results:
            max_sim = max(r['similarity'] for r in results)
            avg_sim = sum(r['similarity'] for r in results) / len(results)
            
            status = "âœ…" if max_sim >= expected_threshold else "âš ï¸"
            print(f"  {status} '{query:30s}' â†’ max={max_sim:.4f}, avg={avg_sim:.4f} (umbral={expected_threshold})")
        else:
            print(f"  âŒ '{query:30s}' â†’ Sin resultados")
    
    # ============================================================================
    # 5. RESUMEN FINAL
    # ============================================================================
    print_header("âœ… RESUMEN DEL DIAGNÃ“STICO")
    
    total_chunks = sum(sources.values())
    total_sources = len(sources)
    new_files_found = sum(1 for nf in new_files if any(nf.lower() in f.lower() for f in sources.keys()))
    
    print(f"""
ğŸ“Š EstadÃ­sticas Generales:
  â€¢ Total de chunks indexados: {total_chunks}
  â€¢ Total de fuentes Ãºnicas: {total_sources}
  â€¢ Archivos nuevos encontrados: {new_files_found}/{len(new_files)}

ğŸ¯ Estado del Sistema:
  â€¢ Vector Store: {'âœ… Operativo' if total_chunks > 0 else 'âŒ VacÃ­o'}
  â€¢ Archivos Nuevos: {'âœ… Indexados correctamente' if new_files_found >= len(new_files) * 0.8 else 'âš ï¸ Algunos faltantes'}
  â€¢ Embeddings: {'âœ… Funcionando' if total_chunks > 0 else 'âŒ Error'}

ğŸ’¡ Recomendaciones:
  â€¢ {'âœ… Sistema listo para demo' if new_files_found >= 5 and total_chunks > 600 else 'âš ï¸ Verificar indexaciÃ³n'}
  â€¢ {'âœ… Calidad de bÃºsqueda adecuada' if total_chunks > 500 else 'âš ï¸ Considerar mÃ¡s documentos'}
    """)
    
    print("=" * 80)
    print("ğŸ‰ DiagnÃ³stico completado".center(80))
    print("=" * 80 + "\n")

if __name__ == "__main__":
    try:
        test_new_documents()
    except Exception as e:
        print(f"\nâŒ Error durante el diagnÃ³stico: {e}")
        import traceback
        traceback.print_exc()

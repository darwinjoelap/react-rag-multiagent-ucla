# Backend Architecture - RAG Multiagent System

## ğŸ“‹ Overview
Sistema RAG (Retrieval Augmented Generation) multiagente usando LangGraph con patrÃ³n ReAct para responder consultas sobre documentos acadÃ©micos de la UCLA.

**TecnologÃ­as principales:**
- **LangGraph**: OrquestaciÃ³n de agentes
- **Ollama (Llama 3.2)**: Modelo de lenguaje local
- **ChromaDB**: Base de datos vectorial
- **LangChain**: Framework de integraciÃ³n
- **Sentence Transformers**: Embeddings semÃ¡nticos

---

## ğŸ—ï¸ Arquitectura General
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Usuario                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Query
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  COORDINATOR AGENT                           â”‚
â”‚  (Analiza query y decide estrategia: search/answer/clarify) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â–º search â”€â”€â”€â”€â”€â”€â”
       â”‚                      â”‚
       â”œâ”€â”€â”€â”€â”€â”€â–º answer â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â–º RESPUESTA FINAL
       â”‚                      â”‚
       â””â”€â”€â”€â”€â”€â”€â–º clarify â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  SEARCH NODE   â”‚
                     â”‚  (ChromaDB)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ Documentos
                              â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  GRADER AGENT  â”‚
                     â”‚  (EvalÃºa docs) â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                           â”‚
           Relevantes                   Irrelevantes
                â”‚                           â”‚
                â–¼                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ANSWER NODE â”‚           â”‚ REWRITER NODEâ”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â””â”€â”€â–º SEARCH (retry)
```

---

## ğŸ§© Componentes Principales

### 1. **State Management** (`state.py`)

**GraphState**: Estado compartido entre todos los nodos del grafo.
```python
class GraphState(TypedDict):
    # Query del usuario
    user_query: str
    
    # PatrÃ³n ReAct
    thought: str          # Razonamiento del agente
    action: str           # AcciÃ³n a ejecutar (search/answer/clarify)
    action_input: str     # Input para la acciÃ³n
    observation: str      # Resultado de la acciÃ³n
    
    # Documentos
    retrieved_documents: List[Dict]
    relevant_context: str
    
    # Respuesta
    final_answer: str
    
    # Control de flujo
    next_step: str
    should_continue: bool
    iteration: int
    
    # Historia
    conversation_history: List[Dict]
    trace: List[Dict]     # Traza ReAct completa
    
    # Metadata
    timestamp: str
```

**Funciones clave:**
- `create_initial_state(query)`: Inicializa estado para nueva consulta
- Gestiona hasta **5 iteraciones** para prevenir bucles infinitos

---

### 2. **Coordinator Agent** (`coordinator.py`)

**Rol**: Cerebro del sistema. Analiza cada query y decide la mejor estrategia.

**Acciones disponibles:**

| AcciÃ³n    | CuÃ¡ndo usar                                          | Output                    |
|-----------|------------------------------------------------------|---------------------------|
| `search`  | Query tÃ©cnica que requiere buscar en documentos     | Query optimizada para bÃºsqueda |
| `answer`  | Ya hay suficiente contexto o es pregunta general    | Respuesta directa          |
| `clarify` | Query ambigua, necesita mÃ¡s informaciÃ³n             | Pregunta de clarificaciÃ³n  |

**Proceso:**
1. Recibe query + contexto (historial, docs previos)
2. Genera prompt con formato ReAct
3. LLM (Llama 3.2) razona y decide acciÃ³n
4. Parsea respuesta: `Thought`, `Action`, `Action Input`
5. Actualiza estado y traza

**Ejemplo de output:**
```
Thought: Pregunta tÃ©cnica sobre un concepto de IA que requiere bÃºsqueda en la base de conocimiento.
Action: search
Action Input: inteligencia artificial definiciÃ³n conceptos fundamentales
```

---

### 3. **Search Node** (`search_node.py`)

**Rol**: Recuperar documentos relevantes de ChromaDB.

**Proceso:**
1. Recibe `action_input` como query de bÃºsqueda
2. Usa `RetrieverService` con parÃ¡metros:
   - `top_k = 5`: MÃ¡ximo 5 documentos
   - `similarity_threshold = 0.2`: Umbral de similitud coseno
3. Retorna documentos con scores de similitud
4. Actualiza `retrieved_documents` en el estado
5. Next step: `grader`

**Logging:**
```python
ğŸ” Search query: 'inteligencia artificial definiciÃ³n'
ğŸ“Š Resultados encontrados: 5
  âœ… Doc: sim=0.4321
  âœ… Doc: sim=0.3307
  ...
```

---

### 4. **Grader Agent** (`grader.py`)

**Rol**: Evaluar si los documentos recuperados son relevantes para la query.

**Proceso:**
1. Para cada documento recuperado:
   - Genera prompt: `Â¿Este documento es relevante para "{query}"?`
   - LLM responde: `relevant` o `irrelevant`
   - Filtra documentos irrelevantes

2. DecisiÃ³n de routing:
```python
   if documentos_relevantes > 0:
       next_step = "answer"
   else:
       next_step = "rewrite"
```

**Ejemplo:**
```
Input: 3 documentos sobre IA
Query: "Â¿QuÃ© es machine learning?"

EvaluaciÃ³n:
  Doc 1: "La IA es..." â†’ relevant âœ…
  Doc 2: "El clima es..." â†’ irrelevant âŒ
  Doc 3: "ML es una rama de la IA..." â†’ relevant âœ…

Output: 2 documentos relevantes â†’ next_step = "answer"
```

---

### 5. **Rewriter Agent** (`rewriter.py`)

**Rol**: Reescribir queries que no produjeron resultados relevantes.

**CuÃ¡ndo se activa:**
- El Grader determinÃ³ que no hay documentos relevantes
- La bÃºsqueda inicial fue muy vaga o mal formulada

**Proceso:**
1. Recibe:
   - Query original del usuario
   - Query anterior que fallÃ³
2. LLM genera versiÃ³n mejorada:
   - MÃ¡s especÃ­fica
   - TÃ©rminos tÃ©cnicos apropiados
   - Enfoque diferente
3. Retorna a `search` con nueva query

**Ejemplo:**
```
Query original: "ExplÃ­came eso"
Query anterior: "eso explicaciÃ³n"

Reescritura: "algoritmos de aprendizaje supervisado en machine learning"
```

---

### 6. **Answer Node** (`answer_node.py`)

**Rol**: Generar la respuesta final al usuario.

**Modos de operaciÃ³n:**

#### A) **Con contexto de documentos**
```python
Input:
  - retrieved_documents (filtrados por Grader)
  - user_query

Proceso:
  1. Formatea contexto de documentos:
     [Documento 1 - fuente.pdf]
     Contenido...
     
     [Documento 2 - fuente2.pdf]
     Contenido...
  
  2. Genera prompt para LLM:
     "BasÃ¡ndote en estos documentos, responde: {query}"
  
  3. LLM sintetiza informaciÃ³n
  
  4. Retorna respuesta citando fuentes

Output:
  "SegÃºn Russell-Norvig.pdf, la inteligencia artificial es..."
```

#### B) **Respuesta directa (sin bÃºsqueda)**
```python
# Para saludos, preguntas meta, etc.
User: "Hola, Â¿cÃ³mo estÃ¡s?"
Answer: "Â¡Hola! Estoy aquÃ­ para ayudarte..."
```

#### C) **ClarificaciÃ³n**
```python
User: "ExplÃ­came eso"
Answer: "Â¿A quÃ© tema especÃ­fico te refieres? Â¿PodrÃ­as darme mÃ¡s detalles?"
```

**Control de flujo:**
```python
should_continue = False  # Siempre termina el grafo
next_step = END
```

---

### 7. **Graph Orchestration** (`graph.py`)

**Estructura LangGraph:**
```python
workflow = StateGraph(GraphState)

# Nodos
workflow.add_node("coordinator", coordinator_node)
workflow.add_node("search", search_node)
workflow.add_node("grader", grader_node)
workflow.add_node("rewrite", rewriter_node)
workflow.add_node("answer", answer_node)

# Edges
workflow.set_entry_point("coordinator")

workflow.add_conditional_edges(
    "coordinator",
    route_decision,  # search / answer / END
)

workflow.add_edge("search", "grader")

workflow.add_conditional_edges(
    "grader",
    route_grader,  # answer / rewrite
)

workflow.add_edge("rewrite", "search")
workflow.add_edge("answer", END)
```

**Funciones de routing:**
```python
def route_decision(state: GraphState) -> str:
    """Enruta desde Coordinator"""
    action = state.get("action", "answer")
    
    if action == "search":
        return "search"
    else:  # answer o clarify
        return "answer"

def route_grader(state: GraphState) -> str:
    """Enruta desde Grader"""
    next_step = state.get("next_step", "answer")
    
    if next_step == "rewrite":
        return "rewrite"
    else:
        return "answer"
```

**FunciÃ³n principal:**
```python
def run_graph(user_query: str) -> GraphState:
    """
    Ejecuta el grafo completo
    
    Args:
        user_query: Pregunta del usuario
        
    Returns:
        GraphState con final_answer y traza completa
    """
    initial_state = create_initial_state(user_query)
    graph = get_graph()
    final_state = graph.invoke(initial_state)
    return final_state
```

---

## ğŸ”„ Flujos de Ejemplo

### **Flujo 1: Query TÃ©cnica Exitosa**
```
Usuario: "Â¿QuÃ© es inteligencia artificial?"
    â†“
Coordinator:
    Thought: "Pregunta tÃ©cnica que requiere documentos"
    Action: search
    Action Input: "inteligencia artificial definiciÃ³n conceptos"
    â†“
Search:
    â†’ Recupera 5 documentos de ChromaDB
    â†’ Similarities: [0.85, 0.78, 0.65, 0.52, 0.45]
    â†“
Grader:
    â†’ EvalÃºa cada documento
    â†’ 4 relevantes, 1 irrelevante
    â†’ Next: answer
    â†“
Answer:
    â†’ Formatea contexto de 4 docs
    â†’ LLM genera sÃ­ntesis
    â†’ "SegÃºn Russell-Norvig.pdf, la IA es el campo de estudio..."
    â†“
FIN âœ…
```

---

### **Flujo 2: Query Vaga â†’ Rewrite â†’ Ã‰xito**
```
Usuario: "ExplÃ­came eso"
    â†“
Coordinator:
    Thought: "Query demasiado vaga"
    Action: clarify
    Action Input: "Â¿A quÃ© tema te refieres?"
    â†“
Answer:
    â†’ "Â¿A quÃ© tema especÃ­fico te refieres? Â¿PodrÃ­as darme mÃ¡s detalles?"
    â†“
FIN âœ…
```

---

### **Flujo 3: BÃºsqueda Fallida â†’ Rewrite**
```
Usuario: "Dame info sobre XYZ raro"
    â†“
Coordinator:
    Action: search
    Action Input: "XYZ raro"
    â†“
Search:
    â†’ Recupera 3 documentos
    â†“
Grader:
    â†’ Los 3 son irrelevantes
    â†’ Next: rewrite
    â†“
Rewriter:
    â†’ "tecnologÃ­a XYZ sistemas computacionales"
    â†’ Action: search
    â†“
Search (2do intento):
    â†’ Recupera documentos diferentes
    â†“
Grader:
    â†’ 2 relevantes
    â†’ Next: answer
    â†“
Answer:
    â†’ Genera respuesta con docs relevantes
    â†“
FIN âœ…
```

---

## âš™ï¸ ConfiguraciÃ³n

### **LLM Settings** (`app/services/llm.py`)
```python
model = "llama3.2:latest"
temperature = 0  # Determinista
base_url = "http://localhost:11434"
```

### **Retriever Settings** (`app/services/retriever.py`)
```python
top_k = 5
similarity_threshold = 0.2  # Cosine similarity
```

### **Embeddings** (`app/services/embeddings.py`)
```python
model_name = "sentence-transformers/all-MiniLM-L6-v2"
dimension = 384
```

### **Graph Limits** (`app/agents/state.py`)
```python
MAX_ITERATIONS = 5  # Previene bucles infinitos
```

---

## ğŸ“Š Traza ReAct

Cada ejecuciÃ³n genera una traza completa:
```json
{
  "query": "Â¿QuÃ© es machine learning?",
  "timestamp": "2026-02-09T18:30:00",
  "iterations": 3,
  "final_answer": "SegÃºn el documento...",
  "trace": [
    {
      "step": 0,
      "agent": "coordinator",
      "timestamp": "2026-02-09T18:30:01",
      "thought": "Pregunta tÃ©cnica...",
      "action": "search",
      "observation": "Decidido: search"
    },
    {
      "step": 1,
      "agent": "search",
      "timestamp": "2026-02-09T18:30:02",
      "thought": "BÃºsqueda en ChromaDB",
      "action": "retrieve",
      "observation": "5 documentos recuperados"
    },
    {
      "step": 2,
      "agent": "grader",
      "timestamp": "2026-02-09T18:30:03",
      "thought": "Evaluando relevancia",
      "action": "grade",
      "observation": "4 relevantes, 1 irrelevante"
    }
  ]
}
```

---

## ğŸ§ª Testing

Ver `notebooks/04_langgraph_agents.ipynb`:

**Tests cubiertos:**
1. âœ… Coordinator - AnÃ¡lisis de queries
2. âœ… MÃºltiples tipos de consultas (tÃ©cnicas, saludos, vagas)
3. âœ… Search Node - RecuperaciÃ³n de documentos
4. âœ… Grader - EvaluaciÃ³n de relevancia
5. âœ… Rewriter - OptimizaciÃ³n de queries
6. âœ… Answer - GeneraciÃ³n de respuestas
7. âœ… Grafo completo end-to-end
8. âœ… Conversaciones multi-turn
9. âœ… LÃ­mites de iteraciones
10. âœ… ExportaciÃ³n de trazas JSON

---

## ğŸ“¦ Dependencias
```txt
langgraph==0.2.62
langchain==0.3.17
langchain-ollama==0.2.2
chromadb==0.5.23
sentence-transformers==3.4.0
```

---

## ğŸš€ Uso

### **Iniciar Ollama**
```bash
ollama serve
ollama pull llama3.2
```

### **Ejecutar Grafo**
```python
from app.agents.graph import run_graph

# Query simple
final_state = run_graph("Â¿QuÃ© es inteligencia artificial?")
print(final_state['final_answer'])

# Acceder a traza
for step in final_state['trace']:
    print(f"{step['agent']}: {step['action']}")
```

### **Testing**
```bash
jupyter notebook notebooks/04_langgraph_agents.ipynb
```

---

## ğŸ“ˆ MÃ©tricas y Observabilidad

**Logging automÃ¡tico:**
- Cada nodo registra su ejecuciÃ³n
- Similarity scores de bÃºsqueda
- Decisiones del Grader
- Reescrituras del Rewriter
- Respuestas generadas

**Traza exportable:**
- JSON completo de cada ejecuciÃ³n
- Guardado en `data/traces/`
- Ãštil para debugging y anÃ¡lisis

---

## ğŸ”œ PrÃ³ximas Mejoras

1. **API REST** (FastAPI) - DÃ­a 6-7
2. **Frontend React** - DÃ­a 8-10
3. **Streaming de respuestas** - DÃ­a 11
4. **Cache de resultados**
5. **MÃ©tricas de performance**
6. **A/B testing de prompts**

---

**Ãšltima actualizaciÃ³n**: Febrero 9, 2026  
**Autor**: Darwin Arroyo - UCLA 
**Autor**: Julio Matheus - UCLA 
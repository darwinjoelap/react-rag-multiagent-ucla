"""
Prompts para agentes LangGraph con patr√≥n ReAct

Estructura:
- Sistema: Definici√≥n del rol y capacidades del agente
- ReAct: Formato Thought ‚Üí Action ‚Üí Action Input
- Few-shot: Ejemplos que gu√≠an el comportamiento
"""

from app.agents.state import get_conversation_context  # ‚Üê NUEVO: Import para multi-turno

# ==============================================================================
# COORDINADOR (AGENT ROUTER)
# ==============================================================================

COORDINATOR_SYSTEM_PROMPT = """Eres el COORDINADOR de un sistema RAG multiagente especializado en an√°lisis de documentos acad√©micos.

# TU ROL
Analizar cada consulta del usuario y decidir la mejor estrategia de acci√≥n.

# ACCIONES DISPONIBLES

## 1. search
Buscar informaci√≥n en la base de conocimiento vectorial.
**Usar cuando:**
- Usuario pregunta sobre contenido espec√≠fico de documentos
- Hay t√©rminos t√©cnicos o conceptos que requieren fundamento
- Necesitas datos, definiciones o explicaciones detalladas

**Generas:** Query optimizada para b√∫squeda sem√°ntica

## 2. answer
Responder directamente sin buscar m√°s informaci√≥n.
**Usar cuando:**
- Ya tienes suficiente contexto de b√∫squedas previas
- Pregunta general que no requiere documentos espec√≠ficos
- Saludo, agradecimiento o pregunta meta sobre el sistema
- Puedes sintetizar informaci√≥n ya recuperada

**Generas:** Respuesta completa al usuario

# FORMATO DE RESPUESTA (ReAct)

SIEMPRE responde en este formato exacto:
```
Thought: [Tu an√°lisis de la situaci√≥n en 1-2 l√≠neas]
Action: [search | answer]
Action Input: [contenido espec√≠fico seg√∫n la acci√≥n]
```

# REGLAS CR√çTICAS

1. **Una acci√≥n por turno** - No combines m√∫ltiples acciones
2. **Queries en espa√±ol** - Todas las b√∫squedas deben ser en espa√±ol
3. **S√© espec√≠fico** - Queries de b√∫squeda deben ser precisas y relevantes
4. **No inventes** - Si no sabes, busca
5. **M√°ximo 5 iteraciones** - S√© eficiente, no busques indefinidamente
6. **Usa contexto previo** - Revisa documentos ya recuperados antes de buscar m√°s
7. **IMPORTANTE - CONTEXTO MULTI-TURNO:** Si el usuario usa palabras como "eso", "aquello", "s√≠", "no", o hace preguntas de seguimiento, revisa el HISTORIAL para entender a qu√© se refiere

# CONTEXTO ACTUAL
- Iteraci√≥n: {iteration}/5
- Documentos en contexto: {num_docs}
- Historial disponible: {has_history}
"""

COORDINATOR_FEW_SHOT_EXAMPLES = """
# EJEMPLOS DE USO

## Ejemplo 1: B√∫squeda de concepto t√©cnico
**Usuario:** "¬øQu√© es machine learning?"

Thought: Pregunta sobre un concepto t√©cnico fundamental que requiere una definici√≥n precisa y completa de la base de conocimiento.
Action: search
Action Input: machine learning definici√≥n conceptos fundamentales

---

## Ejemplo 2: Saludo simple
**Usuario:** "Hola, ¬øc√≥mo est√°s?"

Thought: Es un saludo cordial que no requiere b√∫squeda en documentos.
Action: answer
Action Input: ¬°Hola! Estoy aqu√≠ para ayudarte a encontrar informaci√≥n en los documentos acad√©micos. ¬øQu√© te gustar√≠a saber?

---

## Ejemplo 3: Pregunta de seguimiento (MULTI-TURNO)
**Historial:**
- Usuario: "¬øQu√© es machine learning?"
- Asistente: "El machine learning es un subcampo de la IA..."

**Usuario actual:** "¬øY eso es lo mismo que deep learning?"

Thought: Usuario pregunta sobre la relaci√≥n entre ML (del mensaje anterior) y DL. Debo buscar informaci√≥n sobre esta comparaci√≥n.
Action: search
Action Input: machine learning deep learning relaci√≥n diferencias comparaci√≥n

---

## Ejemplo 4: Respuesta corta con contexto (MULTI-TURNO)
**Historial:**
- Usuario: "¬øLa IA puede aprender sola?"
- Asistente: "S√≠, mediante t√©cnicas de aprendizaje autom√°tico..."

**Usuario actual:** "S√≠"

Thought: Usuario confirma con "s√≠" su inter√©s en el tema. Debo profundizar en el aprendizaje autom√°tico que mencion√©.
Action: search
Action Input: machine learning aprendizaje autom√°tico aut√≥nomo t√©cnicas

---

## Ejemplo 5: Referencia a mensaje anterior (MULTI-TURNO)
**Historial:**
- Usuario: "¬øQu√© son las redes neuronales?"
- Asistente: "Las redes neuronales son modelos inspirados en el cerebro..."

**Usuario actual:** "¬øC√≥mo funciona eso?"

Thought: "Eso" se refiere a las redes neuronales del mensaje anterior. Debo buscar informaci√≥n sobre su funcionamiento.
Action: search
Action Input: redes neuronales funcionamiento arquitectura proceso

---

## Ejemplo 6: Respuesta con contexto suficiente
**Usuario:** "Resume lo que encontraste"
**Contexto:** Ya hay 5 documentos sobre transformers recuperados

Thought: Tengo suficientes documentos recuperados sobre transformers. Puedo sintetizar la informaci√≥n sin buscar m√°s.
Action: answer
Action Input: Bas√°ndome en los documentos, los transformers son arquitecturas de redes neuronales que revolucionaron el NLP mediante el mecanismo de atenci√≥n...

---

## Ejemplo 7: B√∫squeda con m√∫ltiples conceptos
**Usuario:** "Compara supervised learning vs unsupervised learning"

Thought: Necesito informaci√≥n espec√≠fica sobre ambos paradigmas de aprendizaje para hacer una comparaci√≥n precisa.
Action: search
Action Input: supervised learning unsupervised learning diferencias comparaci√≥n

---

## Ejemplo 8: B√∫squeda de disponibilidad
**Usuario:** "¬øTienes informaci√≥n sobre reinforcement learning?"

Thought: Usuario pregunta si tengo informaci√≥n disponible. Debo buscar para verificar qu√© documentos existen.
Action: search
Action Input: reinforcement learning aprendizaje por refuerzo
"""

def format_coordinator_prompt(state: dict) -> str:
    """
    Formatear prompt del coordinador con el estado actual
    
    Args:
        state: Estado actual del grafo (GraphState)
        
    Returns:
        Prompt completo formateado con contexto
    """
    # Extraer informaci√≥n del estado
    num_docs = len(state.get("retrieved_documents", []))
    iteration = state.get("iteration", 0)
    
    # ========== NUEVO: SOPORTE MULTI-TURNO ==========
    # Obtener historial de conversaci√≥n usando la funci√≥n del state
    conversation_history_text = ""
    messages = state.get("messages", [])
    
    if len(messages) > 1:  # Hay conversaci√≥n previa
        conversation_history_text = "\n\n## üí¨ HISTORIAL DE LA CONVERSACI√ìN (√∫ltimos 5 mensajes)\n\n"
        conversation_history_text += get_conversation_context(state, last_n=5)
        has_history = "S√≠"
    else:
        has_history = "No"
    # ================================================
    
    # Formatear prompt del sistema
    system_prompt = COORDINATOR_SYSTEM_PROMPT.format(
        iteration=iteration,
        num_docs=num_docs,
        has_history=has_history
    )
    
    # Construir resumen de documentos disponibles
    docs_summary = ""
    if num_docs > 0:
        docs_summary = f"\n\n## üìö DOCUMENTOS EN CONTEXTO\nActualmente tienes {num_docs} documentos recuperados de b√∫squedas previas.\n"
        
        # Listar fuentes √∫nicas
        sources = set()
        for doc in state.get("retrieved_documents", []):
            source = doc.get("metadata", {}).get("source", "Desconocido")
            sources.add(source)
        
        if sources:
            docs_summary += f"**Fuentes disponibles:** {', '.join(list(sources)[:3])}"
            if len(sources) > 3:
                docs_summary += f" (y {len(sources) - 3} m√°s)"
    
    # Advertencia de iteraciones
    iteration_warning = ""
    if iteration >= 3:
        iteration_warning = f"\n\n‚ö†Ô∏è **ADVERTENCIA:** Est√°s en la iteraci√≥n {iteration}/5. S√© m√°s decidido en tu pr√≥xima acci√≥n.\n"
    
    # Construir prompt completo
    full_prompt = f"""{system_prompt}

{COORDINATOR_FEW_SHOT_EXAMPLES}
{conversation_history_text}
{docs_summary}
{iteration_warning}

# üéØ CONSULTA ACTUAL DEL USUARIO
**Usuario:** {state.get("current_query", "")}

# TU RESPUESTA
Analiza y responde en formato ReAct:
"""
    
    return full_prompt


# ==============================================================================
# ANSWER NODE - NUEVO PROMPT CON MULTI-TURNO
# ==============================================================================

def format_answer_prompt(state: dict) -> str:
    """
    Formatear prompt del nodo answer con contexto conversacional
    
    Args:
        state: Estado actual del grafo (GraphState)
        
    Returns:
        Prompt completo para generar la respuesta final
    """
    
    # Obtener historial de conversaci√≥n (√∫ltimos 3 turnos)
    conversation_history_text = ""
    messages = state.get("messages", [])
    
    if len(messages) > 1:
        conversation_history_text = "## üí¨ CONTEXTO DE LA CONVERSACI√ìN\n\n"
        conversation_history_text += get_conversation_context(state, last_n=3)
        conversation_history_text += "\n"
    
    # Consulta actual
    current_query = state.get("current_query", "")
    
    # Documentos recuperados
    docs = state.get("retrieved_documents", [])
    
    # Formatear contexto de documentos
    context = ""
    if docs:
        context = "## üìö DOCUMENTOS RELEVANTES\n\n"
        for i, doc in enumerate(docs[:5], 1):
            doc_content = doc.get("document", "")
            source = doc.get("metadata", {}).get("source", "Desconocido")
            similarity = doc.get("similarity", 0.0)
            
            context += f"**[Documento {i}]** (Fuente: {source} | Similitud: {similarity:.2%})\n"
            context += f"{doc_content[:500]}...\n\n"
    else:
        context = "## ‚ÑπÔ∏è INFORMACI√ìN\nNo se encontraron documentos relevantes en la base de conocimiento.\n\n"
    
    # Construir prompt
    prompt = f"""Eres un asistente experto en inteligencia artificial y an√°lisis de documentos acad√©micos.

{conversation_history_text}

{context}

## üéØ CONSULTA ACTUAL
**Usuario:** "{current_query}"

## üìã INSTRUCCIONES

1. **CONTEXTO MULTI-TURNO:** 
   - Si el usuario usa "s√≠", "no", "eso", "aquello" u otras referencias, consulta el HISTORIAL para entender a qu√© se refiere
   - Si es una pregunta de seguimiento ("¬øy eso qu√© es?", "¬øc√≥mo funciona?"), usa el contexto de mensajes anteriores

2. **USO DE DOCUMENTOS:**
   - Si hay documentos relevantes, √∫salos para fundamentar tu respuesta
   - Cita las fuentes cuando uses informaci√≥n de los documentos
   - Si no hay documentos pero tienes conocimiento general, puedes usarlo

3. **ESTILO DE RESPUESTA:**
   - S√© conciso pero completo
   - Usa un lenguaje claro y profesional
   - Estructura la informaci√≥n de forma l√≥gica
   - Si el usuario pide aclaraci√≥n sobre algo anterior, revisa el historial

4. **FORMATO:**
   - Responde SOLO con el texto de la respuesta
   - NO incluyas "Thought:", "Action:", ni otros metadatos
   - NO uses markdown extremo, mant√©n formato simple

## ‚úçÔ∏è TU RESPUESTA

Responde a la consulta del usuario considerando todo el contexto disponible:
"""
    
    return prompt


# ==============================================================================
# UTILIDADES PARA PARSING
# ==============================================================================

def parse_react_response(response: str) -> dict:
    """
    Parsear respuesta en formato ReAct
    
    Extrae:
    - Thought: L√≠nea que empieza con "Thought:"
    - Action: L√≠nea que empieza con "Action:"
    - Action Input: L√≠nea que empieza con "Action Input:"
    
    Args:
        response: Respuesta del LLM en formato ReAct
        
    Returns:
        Diccionario con thought, action, action_input
    """
    lines = response.strip().split('\n')
    
    result = {
        "thought": "",
        "action": "",
        "action_input": ""
    }
    
    current_field = None
    
    for line in lines:
        line = line.strip()
        
        if line.startswith("Thought:"):
            current_field = "thought"
            result["thought"] = line.replace("Thought:", "").strip()
        elif line.startswith("Action:"):
            current_field = "action"
            result["action"] = line.replace("Action:", "").strip().lower()
        elif line.startswith("Action Input:"):
            current_field = "action_input"
            result["action_input"] = line.replace("Action Input:", "").strip()
        elif current_field and line:
            # L√≠nea de continuaci√≥n
            result[current_field] += " " + line
    
    # Validar que la acci√≥n sea v√°lida
    valid_actions = ["search", "answer"]  # ‚Üê MODIFICADO: Removido "clarify"
    if result["action"] not in valid_actions:
        # Si la acci√≥n es inv√°lida, forzar a "search" por defecto
        print(f"‚ö†Ô∏è Acci√≥n inv√°lida detectada: {result['action']}. Usando 'search' por defecto.")
        result["action"] = "search"
    
    return result